{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e401a58",
   "metadata": {},
   "source": [
    "# Implementacion de Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640efd02",
   "metadata": {},
   "source": [
    "## 1. Introduccion\n",
    "\n",
    "En esta etapa se implementa un modelo de red neuronal utilizando PyTorch con el objetivo de predecir el precio de las propiedades, para eso se utilizara una arquitectura MLP, adecuada para datos tabulares estructurados. Luego se comparara este modelo contra los modelos clasicos de ML entrenados en dicha etapa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a2353",
   "metadata": {},
   "source": [
    "## 2. Importacion de librerias y carga del dataset procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aa3a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a27170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/listings_processed.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e7595c",
   "metadata": {},
   "source": [
    "### 2.1 Separacion de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a394fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']  #Variable objetivo \n",
    "X = df.drop(columns=['price'])  #Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855c197",
   "metadata": {},
   "source": [
    "### 2.3 Escalado de datos\n",
    "\n",
    "Las redes neuronales son sensibles a la escala de los datos, por lo que se aplica estandarización tanto a las variables predictoras como a la variable objetivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa557cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test  = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_test  = scaler_y.transform(y_test.values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d5b995",
   "metadata": {},
   "source": [
    "### 2.4 Conversion a tensores de PyTorch\n",
    "\n",
    "Los datos deben convertirse a tensores para poder ser utilizados por el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc81b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "171ebf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset   = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b94f5a6",
   "metadata": {},
   "source": [
    "## 3. Definicion del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54275624",
   "metadata": {},
   "source": [
    "### 3.1 Importacion de modulos desde src\n",
    "\n",
    "Se importa la arquitectura MLP definida en `src/deep_learning/model.py` y la función de entrenamiento definida en `src/deep_learning/train.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f57a8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.deep_learning.model import MLPRegressor\n",
    "from src.deep_learning.train import train_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2eb06d",
   "metadata": {},
   "source": [
    "### 3.2 Inicializacion de modelo \n",
    "\n",
    "Dimension de entrada en funcion del numero de variables predictoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8e98122",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = MLPRegressor(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018cb26",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento del modelo\n",
    "\n",
    "Se entrena el modelo utilizando función de pérdida MSE y optimizador Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b7709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 2651.1146 | Val Loss: 62.4456\n",
      "Epoch 2 | Train Loss: 280.0082 | Val Loss: 51.6213\n",
      "Epoch 3 | Train Loss: 249.3764 | Val Loss: 53.4672\n",
      "Epoch 4 | Train Loss: 214.5918 | Val Loss: 34.7725\n",
      "Epoch 5 | Train Loss: 205.6865 | Val Loss: 34.7145\n",
      "Epoch 6 | Train Loss: 191.1895 | Val Loss: 34.0810\n",
      "Epoch 7 | Train Loss: 182.7085 | Val Loss: 29.1673\n",
      "Epoch 8 | Train Loss: 171.7605 | Val Loss: 24.8766\n",
      "Epoch 9 | Train Loss: 161.6809 | Val Loss: 27.3297\n",
      "Epoch 10 | Train Loss: 153.1351 | Val Loss: 21.7263\n",
      "Epoch 11 | Train Loss: 140.9143 | Val Loss: 20.4821\n",
      "Epoch 12 | Train Loss: 132.4370 | Val Loss: 19.5609\n",
      "Epoch 13 | Train Loss: 122.2874 | Val Loss: 20.9994\n",
      "Epoch 14 | Train Loss: 114.0790 | Val Loss: 22.5177\n",
      "Epoch 15 | Train Loss: 104.6827 | Val Loss: 21.3492\n",
      "Epoch 16 | Train Loss: 98.3945 | Val Loss: 17.8601\n",
      "Epoch 17 | Train Loss: 91.9898 | Val Loss: 18.3084\n",
      "Epoch 18 | Train Loss: 88.2635 | Val Loss: 19.9080\n",
      "Epoch 19 | Train Loss: 81.3746 | Val Loss: 18.8221\n",
      "Epoch 20 | Train Loss: 80.2914 | Val Loss: 19.7203\n",
      "Epoch 21 | Train Loss: 76.6505 | Val Loss: 17.3336\n",
      "Epoch 22 | Train Loss: 76.1210 | Val Loss: 17.4213\n",
      "Epoch 23 | Train Loss: 74.9674 | Val Loss: 19.0558\n",
      "Epoch 24 | Train Loss: 72.5518 | Val Loss: 18.3356\n",
      "Epoch 25 | Train Loss: 72.0986 | Val Loss: 16.7307\n",
      "Epoch 26 | Train Loss: 71.9618 | Val Loss: 16.7924\n",
      "Epoch 27 | Train Loss: 71.5760 | Val Loss: 16.8337\n",
      "Epoch 28 | Train Loss: 71.2284 | Val Loss: 19.5757\n",
      "Epoch 29 | Train Loss: 71.4558 | Val Loss: 16.7185\n",
      "Epoch 30 | Train Loss: 71.3076 | Val Loss: 16.7062\n",
      "Epoch 31 | Train Loss: 70.0794 | Val Loss: 16.5145\n",
      "Epoch 32 | Train Loss: 70.4036 | Val Loss: 16.6917\n",
      "Epoch 33 | Train Loss: 69.2371 | Val Loss: 17.1201\n",
      "Epoch 34 | Train Loss: 69.8758 | Val Loss: 17.3870\n",
      "Epoch 35 | Train Loss: 69.8291 | Val Loss: 16.6623\n",
      "Epoch 36 | Train Loss: 69.7240 | Val Loss: 17.4324\n",
      "Epoch 37 | Train Loss: 68.2829 | Val Loss: 16.6091\n",
      "Epoch 38 | Train Loss: 68.1238 | Val Loss: 16.6117\n",
      "Epoch 39 | Train Loss: 67.6239 | Val Loss: 16.4028\n",
      "Epoch 40 | Train Loss: 67.5675 | Val Loss: 16.6334\n",
      "Epoch 41 | Train Loss: 68.7404 | Val Loss: 16.4465\n",
      "Epoch 42 | Train Loss: 67.6730 | Val Loss: 16.4342\n",
      "Epoch 43 | Train Loss: 67.5148 | Val Loss: 16.4752\n",
      "Epoch 44 | Train Loss: 66.9075 | Val Loss: 16.6740\n",
      "Epoch 45 | Train Loss: 66.9577 | Val Loss: 16.4640\n",
      "Epoch 46 | Train Loss: 66.5219 | Val Loss: 16.5932\n",
      "Epoch 47 | Train Loss: 66.1310 | Val Loss: 16.6605\n",
      "Epoch 48 | Train Loss: 66.1475 | Val Loss: 16.4353\n",
      "Epoch 49 | Train Loss: 66.0216 | Val Loss: 16.5370\n",
      "Epoch 50 | Train Loss: 65.6654 | Val Loss: 16.3390\n",
      "Epoch 51 | Train Loss: 65.9886 | Val Loss: 16.5831\n",
      "Epoch 52 | Train Loss: 65.4152 | Val Loss: 16.7427\n",
      "Epoch 53 | Train Loss: 64.8371 | Val Loss: 16.3864\n",
      "Epoch 54 | Train Loss: 64.9808 | Val Loss: 16.5232\n",
      "Epoch 55 | Train Loss: 64.6541 | Val Loss: 16.7433\n",
      "Epoch 56 | Train Loss: 65.1054 | Val Loss: 16.5195\n",
      "Epoch 57 | Train Loss: 64.1048 | Val Loss: 17.3160\n",
      "Epoch 58 | Train Loss: 64.4950 | Val Loss: 17.1983\n",
      "Epoch 59 | Train Loss: 64.4360 | Val Loss: 16.5217\n",
      "Epoch 60 | Train Loss: 63.6431 | Val Loss: 16.4046\n",
      "Epoch 61 | Train Loss: 64.5576 | Val Loss: 16.3415\n",
      "Epoch 62 | Train Loss: 63.3500 | Val Loss: 16.3451\n",
      "Epoch 63 | Train Loss: 63.8003 | Val Loss: 16.5443\n",
      "Epoch 64 | Train Loss: 63.6883 | Val Loss: 16.4197\n",
      "Epoch 65 | Train Loss: 63.1178 | Val Loss: 17.0813\n",
      "Early stopping activado\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,\n",
    "                    X_train,\n",
    "                    y_train, \n",
    "                    epochs=100, \n",
    "                    lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa40c1b",
   "metadata": {},
   "source": [
    "## 5.Evaluacion del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68e9050",
   "metadata": {},
   "source": [
    "### 5.1 Generacion de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db50f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab685b",
   "metadata": {},
   "source": [
    "### 5.2 Reversion del escalado\n",
    "\n",
    "Las predicciones y valores reales se transforman nuevamente a su escala original para una correcta interpretación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab6000c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m predictions_mlp = predictions.detach().cpu().numpy()\n\u001b[32m      2\u001b[39m y_test_mlp = y_test.detach().cpu().numpy()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m predictions_original = \u001b[43mscaler_y\u001b[49m.inverse_transform(predictions_mlp)\n\u001b[32m      5\u001b[39m y_test_original = scaler_y.inverse_transform(y_test_mlp)\n",
      "\u001b[31mNameError\u001b[39m: name 'scaler_y' is not defined"
     ]
    }
   ],
   "source": [
    "predictions_mlp = predictions.detach().cpu().numpy()\n",
    "y_test_mlp = y_test.detach().cpu().numpy()\n",
    "\n",
    "predictions_original = scaler_y.inverse_transform(predictions_mlp)\n",
    "y_test_original = scaler_y.inverse_transform(y_test_mlp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5e507f",
   "metadata": {},
   "source": [
    "### 5.3 Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90bf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Multilayer Perceptron: 1157.86\n",
      "RMSE Multilayer Perceptron: 2091.30\n",
      "R² Multilayer Perceptron: 0.4032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,root_mean_squared_error,r2_score\n",
    "\n",
    "mae_mlp = mean_absolute_error(y_test_original,predictions_original)\n",
    "rmse_mlp = root_mean_squared_error(y_test_original,predictions_original)\n",
    "r2_mlp = r2_score(y_test_original,predictions_original)\n",
    "\n",
    "print(f\"MAE Multilayer Perceptron: {mae_mlp:.2f}\")\n",
    "print(f\"RMSE Multilayer Perceptron: {rmse_mlp:.2f}\")\n",
    "print(f\"R² Multilayer Perceptron: {r2_mlp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534afea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio real: 2871.589599609375\n",
      "Promedio predicho: 2840.170654296875\n"
     ]
    }
   ],
   "source": [
    "print(\"Promedio real:\", y_test_original.mean().item())\n",
    "print(\"Promedio predicho:\", predictions_original.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec001b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.xboost import train_xgboost\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_15616\\96034308.py:4: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  y_test_real = np.expm1(y_test)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_model = train_xgboost(X_train,y_train)\n",
    "preds_xgb = xgb_model.predict(X_test)\n",
    "preds_real = np.expm1(preds_xgb)\n",
    "y_test_real = np.expm1(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00a79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Multilayer Perceptron: 15.24\n",
      "RMSE Multilayer Perceptron: 360.01\n",
      "R² Multilayer Perceptron: 0.0556\n"
     ]
    }
   ],
   "source": [
    "mae_xb = mean_absolute_error(y_test_real,preds_real)\n",
    "rmse_xb = root_mean_squared_error(y_test_real,preds_real)\n",
    "r2_xb = r2_score(y_test_real,preds_real)\n",
    "\n",
    "print(f\"MAE Multilayer Perceptron: {mae_xb:.2f}\")\n",
    "print(f\"RMSE Multilayer Perceptron: {rmse_xb:.2f}\")\n",
    "print(f\"R² Multilayer Perceptron: {r2_xb:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
